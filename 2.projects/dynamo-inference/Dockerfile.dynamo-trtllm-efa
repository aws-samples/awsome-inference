# syntax=docker/dockerfile:1.10.0
#
# Dockerfile.python-base-cuda13 - TensorRT-LLM with ENFORCED CUDA 13.x
#
# This Dockerfile ensures CUDA 13 consistency by:
# 1. Using CUDA 13.0 base image
# 2. Build-time verification of CUDA libraries
# 3. Runtime startup check before application launch
# 4. Failing fast on version mismatch
#

##############################
# CUDA 13 Base Image
##############################
# IMPORTANT: Use explicit CUDA 13.0 base image
# This ensures all CUDA libraries are version 13.x
ARG CUDA_VERSION=13.0.0
ARG UBUNTU_VERSION=22.04
FROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu${UBUNTU_VERSION} AS base

# Verify we're using CUDA 13 at build time
RUN nvcc --version | grep -q "release 13" || { \
    echo "ERROR: Base image is not CUDA 13.x!"; \
    nvcc --version; \
    exit 1; \
}

##############################
# Build Arguments
##############################
ARG NPROC
ARG ARCH="x86_64"

# Versions - PINNED for CUDA 13 compatibility
ARG DEFAULT_PYTHON_VERSION="3.12"
ARG NIXL_VERSION="0.7.1"
ARG NIXL_GIT_TAG="${NIXL_VERSION}"
ARG DYNAMO_GIT_TAG="main"
ARG RUST_TOOLCHAIN="1.86.0"

# CUDA version enforcement
ARG REQUIRED_CUDA_MAJOR=13
ARG REQUIRED_CUDA_MINOR=0
ARG MIN_DRIVER_VERSION=555

##############################
# Path Configuration
##############################
ARG CUDA_HOME="/usr/local/cuda"
ARG EFA_PREFIX="/opt/amazon/efa"
ARG GDRCOPY_PREFIX="/opt/gdrcopy"
ARG UCX_PREFIX="/usr/local/ucx"
ARG AWS_OFI_NCCL_PREFIX="/opt/aws-ofi-nccl"
ARG LIBFABRIC_PREFIX="/usr/local"

# NIXL paths
ARG NIXL_PREFIX="/usr/local/nixl"
ARG NIXL_LIB_DIR="${NIXL_PREFIX}/lib/${ARCH}-linux-gnu"
ARG NIXL_PLUGIN_DIR="${NIXL_PREFIX}/lib/${ARCH}-linux-gnu/plugins"

# Python paths
ARG PYTHON_VERSION="3.12"
ARG PYTHON_SITE_PACKAGES="/usr/local/lib/python${PYTHON_VERSION}/dist-packages"

# Application paths
ARG DYNAMO_HOME="/opt/dynamo"
ARG NIXL_BUILD_DIR="/workspace/nixl"

# Rust paths
ARG RUSTUP_HOME="/usr/local/rustup"
ARG CARGO_HOME="/usr/local/cargo"

##############################
# Derived paths
##############################
ARG TORCH_LIB_DIR="${PYTHON_SITE_PACKAGES}/torch/lib"
ARG TENSORRT_LLM_DIR="${PYTHON_SITE_PACKAGES}/tensorrt_llm"
ARG TENSORRT_LLM_LIBS="${TENSORRT_LLM_DIR}/libs"
ARG TENSORRT_DIR="${PYTHON_SITE_PACKAGES}/tensorrt"

##############################
# Environment Variables
##############################
ENV LANG=C.UTF-8 \
    LC_ALL=C.UTF-8 \
    PIP_BREAK_SYSTEM_PACKAGES=1 \
    # CUDA Version Enforcement
    REQUIRED_CUDA_MAJOR=${REQUIRED_CUDA_MAJOR} \
    REQUIRED_CUDA_MINOR=${REQUIRED_CUDA_MINOR} \
    MIN_DRIVER_VERSION=${MIN_DRIVER_VERSION} \
    CUDA_VERSION_ENFORCED=true \
    # Rust
    RUSTUP_HOME=${RUSTUP_HOME} \
    CARGO_HOME=${CARGO_HOME} \
    # CUDA
    CUDA_HOME=${CUDA_HOME} \
    # Paths from base
    EFA_PATH=${EFA_PREFIX} \
    GDRCOPY_PATH=${GDRCOPY_PREFIX} \
    UCX_PATH=${UCX_PREFIX} \
    # NIXL
    NIXL_PREFIX=${NIXL_PREFIX} \
    NIXL_LIB_DIR=${NIXL_LIB_DIR} \
    NIXL_PLUGIN_DIR=${NIXL_PLUGIN_DIR} \
    # Dynamo
    DYNAMO_HOME=${DYNAMO_HOME} \
    # Python paths for Dynamo
    PYTHONPATH=${DYNAMO_HOME}/components/backends/trtllm/src:${DYNAMO_HOME}/components/frontend/src \
    # System PATH
    PATH=${CARGO_HOME}/bin:${CUDA_HOME}/bin:/usr/local/bin:${PATH}

##############################
# Build-time CUDA Verification
##############################
RUN echo "=== Build-time CUDA 13 Verification ===" && \
    # Check nvcc version
    NVCC_VERSION=$(nvcc --version | grep "release" | awk '{print $5}' | cut -d',' -f1) && \
    NVCC_MAJOR=$(echo $NVCC_VERSION | cut -d'.' -f1) && \
    echo "NVCC version: $NVCC_VERSION (major: $NVCC_MAJOR)" && \
    if [ "$NVCC_MAJOR" != "${REQUIRED_CUDA_MAJOR}" ]; then \
        echo "ERROR: NVCC version $NVCC_VERSION doesn't match required CUDA ${REQUIRED_CUDA_MAJOR}"; \
        exit 1; \
    fi && \
    # Check CUDA libraries
    echo "Checking CUDA ${REQUIRED_CUDA_MAJOR} libraries..." && \
    ls -la /usr/local/cuda/lib64/libcudart.so* && \
    ls -la /usr/local/cuda/lib64/libcublas.so* && \
    echo "✅ CUDA ${REQUIRED_CUDA_MAJOR} build environment verified"

##############################
# Install System Dependencies
##############################
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        python3 \
        python3-dev \
        python3-pip \
        python-is-python3 \
        openmpi-bin \
        libopenmpi-dev \
        git \
        build-essential \
        pkg-config \
        libhwloc-dev \
        curl \
        wget \
        protobuf-compiler \
        libprotobuf-dev \
        libzmq5 \
        libcpprest-dev \
        libgrpc++-dev \
        libgrpc-dev \
        jq \
    && rm -rf /var/lib/apt/lists/*


##############################
# Install OpenSSH for Distributed Training
##############################
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        openssh-client \
        openssh-server \
        ninja-build \
        patchelf \
    && rm -rf /var/lib/apt/lists/* \
    && mkdir -p /var/run/sshd \
    && cat /etc/ssh/ssh_config | grep -v StrictHostKeyChecking > /etc/ssh/ssh_config.new \
    && echo "    StrictHostKeyChecking no" >> /etc/ssh/ssh_config.new \
    && mv /etc/ssh/ssh_config.new /etc/ssh/ssh_config \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Configure OpenSSH
RUN mkdir -p /var/run/sshd && \
    sed 's@session\s*required\s*pam_loginuid.so@session optional pam_loginuid.so@g' -i /etc/pam.d/sshd

# Generate SSH keys
RUN rm -rf /root/.ssh/ && \
    mkdir -p /root/.ssh/ && \
    ssh-keygen -q -t rsa -N '' -f /root/.ssh/id_rsa && \
    cp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys && \
    printf "Host *\n  StrictHostKeyChecking no\n" >> /root/.ssh/config



##############################
# Install Rust Toolchain
##############################
RUN curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | \
    sh -s -- -y --no-modify-path --profile minimal --default-toolchain ${RUST_TOOLCHAIN} && \
    chmod -R a+w ${RUSTUP_HOME} ${CARGO_HOME} && \
    rustc --version && cargo --version

##############################
# Build NIXL Python Bindings
##############################
WORKDIR ${NIXL_BUILD_DIR}
RUN rm -rf nixl && \
    git clone --depth 1 --branch "${NIXL_GIT_TAG}" \
        https://github.com/ai-dynamo/nixl.git ${NIXL_BUILD_DIR}

RUN python3 -m pip install --no-cache-dir \
        meson meson-python pybind11 tomlkit && \
    python3 -m pip install --no-cache-dir . && \
    python3 -m pip install --no-cache-dir "nixl==${NIXL_VERSION}"

##############################
# Clone Dynamo
##############################
RUN git clone https://github.com/ai-dynamo/dynamo.git ${DYNAMO_HOME} && \
    cd ${DYNAMO_HOME} && \
    git checkout "${DYNAMO_GIT_TAG}"

##############################
# Build Dynamo Rust Bindings
##############################
RUN python3 -m pip install --no-cache-dir maturin

WORKDIR ${DYNAMO_HOME}/lib/bindings/python
RUN maturin build --release --locked -j ${NPROC:-$(nproc)} && \
    python3 -m pip install --no-cache-dir target/wheels/*.whl

##############################
# Install FlashInfer (OPTIONAL - may not have CUDA 13 wheels)
##############################
# FlashInfer is optional for TensorRT-LLM - it provides attention optimizations
# but TRT-LLM works without it. As of now, FlashInfer only has wheels for:
# - CUDA 12.1, 12.4, 12.6
# - PyTorch 2.4, 2.5, 2.6
# CUDA 13 and PyTorch 2.9+ wheels may not be available yet.
RUN echo "=== Attempting FlashInfer Installation (Optional) ===" && \
    CUDA_VERSION=$(nvcc --version | grep "release" | awk '{print $5}' | cut -d',' -f1) && \
    CUDA_MAJOR=$(echo $CUDA_VERSION | cut -d'.' -f1) && \
    CUDA_MINOR=$(echo $CUDA_VERSION | cut -d'.' -f2) && \
    TORCH_VERSION=$(python3 -c "import torch; v=torch.__version__.split('+')[0].split('.'); print(f'{v[0]}{v[1]}')" 2>/dev/null || echo "unknown") && \
    echo "Detected: CUDA ${CUDA_VERSION}, PyTorch version code: ${TORCH_VERSION}" && \
    # Try multiple fallback options
    ( \
        # Option 1: Try exact CUDA version
        python3 -m pip install --no-cache-dir flashinfer-python \
            -i "https://flashinfer.ai/whl/cu${CUDA_MAJOR}${CUDA_MINOR}/torch${TORCH_VERSION}/" 2>/dev/null && \
        echo "✅ FlashInfer installed from cu${CUDA_MAJOR}${CUDA_MINOR}/torch${TORCH_VERSION}" \
    ) || ( \
        # Option 2: Try cu126 (closest to cu130)
        python3 -m pip install --no-cache-dir flashinfer-python \
            -i "https://flashinfer.ai/whl/cu126/torch26/" 2>/dev/null && \
        echo "✅ FlashInfer installed from cu126/torch26 (fallback)" \
    ) || ( \
        # Option 3: Try cu124
        python3 -m pip install --no-cache-dir flashinfer-python \
            -i "https://flashinfer.ai/whl/cu124/torch26/" 2>/dev/null && \
        echo "✅ FlashInfer installed from cu124/torch26 (fallback)" \
    ) || ( \
        # Option 4: Skip FlashInfer entirely
        echo "⚠️  FlashInfer not available for CUDA ${CUDA_VERSION} / PyTorch ${TORCH_VERSION}" && \
        echo "⚠️  TensorRT-LLM will use default attention backend (still functional)" && \
        echo "⚠️  This is OK - FlashInfer is an optional optimization" \
    )

##############################
# Install Dynamo with TensorRT-LLM
# NOTE: Must use TensorRT-LLM built for CUDA 13
##############################
WORKDIR ${DYNAMO_HOME}
RUN echo "=== Installing Dynamo with TensorRT-LLM (CUDA ${REQUIRED_CUDA_MAJOR}) ===" && \
    # Install with --no-deps for flashinfer to avoid the broken PyPI package
    python3 -m pip install --no-cache-dir \
        --extra-index-url https://pypi.nvidia.com/ \
        -e ".[trtllm]" \
        --no-build-isolation || \
    # Fallback: install without flashinfer constraint
    ( \
        echo "Retrying without flashinfer constraint..." && \
        # First install tensorrt-llm without flashinfer
        python3 -m pip install --no-cache-dir \
            --extra-index-url https://pypi.nvidia.com/ \
            tensorrt-llm --no-deps && \
        # Then install other deps
        python3 -m pip install --no-cache-dir \
            --extra-index-url https://pypi.nvidia.com/ \
            -e "." \
    ) && \
    echo "✅ Dynamo installed"

##############################
# Set LD_LIBRARY_PATH
##############################
ENV LD_LIBRARY_PATH="\
${PYTHON_SITE_PACKAGES}/torch/lib:\
${PYTHON_SITE_PACKAGES}/tensorrt_libs:\
${PYTHON_SITE_PACKAGES}/tensorrt_llm/libs:\
${TORCH_LIB_DIR}:\
${TENSORRT_LLM_LIBS}:\
${TENSORRT_DIR}:\
/usr/local/lib:\
${NIXL_LIB_DIR}:\
${NIXL_PLUGIN_DIR}:\
${UCX_PREFIX}/lib:\
${UCX_PREFIX}/lib/ucx:\
${LIBFABRIC_PREFIX}/lib:\
${EFA_PREFIX}/lib:\
${GDRCOPY_PREFIX}/lib64:\
${AWS_OFI_NCCL_PREFIX}/lib:\
${CUDA_HOME}/lib64:\
${LD_LIBRARY_PATH}"

##############################
# Build-time Validation
##############################

# 1. Verify CUDA 13 libraries are present
RUN echo "=== Verifying CUDA ${REQUIRED_CUDA_MAJOR} Libraries ===" && \
    ldconfig -p | grep libcublas && \
    ldconfig -p | grep -q "libcublasLt.so.${REQUIRED_CUDA_MAJOR}" && \
    echo "✅ libcublasLt.so.${REQUIRED_CUDA_MAJOR} FOUND"

# 2. Verify Python packages
# RUN python3 -c "\
# import torch; \
# import importlib.metadata as im; \
# cuda_version = torch.version.cuda; \
# cuda_major = int(cuda_version.split('.')[0]); \
# print(f'PyTorch CUDA: {cuda_version}'); \
# assert cuda_major >= ${REQUIRED_CUDA_MAJOR}, f'PyTorch CUDA {cuda_version} < required ${REQUIRED_CUDA_MAJOR}'; \
# print(f'✅ PyTorch CUDA version OK: {cuda_version}'); \
# print(f'✅ TensorRT-LLM: {im.version(\"tensorrt-llm\")}'); \
# print(f'✅ NIXL: {im.version(\"nixl\")}'); \
# # Check FlashInfer (optional)
# try: \
#     print(f'✅ FlashInfer: {im.version(\"flashinfer-python\")}'); \
# except: \
#     print('⚠️  FlashInfer: not installed (optional)'); \
# "

# 3. Verify critical shared libraries link to CUDA 13
RUN echo "=== Checking Library Dependencies ===" && \
    BINDINGS=$(find ${TENSORRT_LLM_DIR} -name "bindings*.so" 2>/dev/null | head -1) && \
    if [ -n "$BINDINGS" ]; then \
        echo "Checking: $BINDINGS"; \
        ldd "$BINDINGS" 2>/dev/null | grep -E "cuda|cublas" | head -5; \
        # Verify no CUDA 12 libraries linked
        if ldd "$BINDINGS" 2>/dev/null | grep -q "libcudart.so.12"; then \
            echo "⚠️  WARNING: Found CUDA 12 library reference - may cause runtime issues"; \
        else \
            echo "✅ No CUDA 12 library references found"; \
        fi; \
    fi

# 4. Verify SSH
RUN echo "=== Verifying SSH ===" && \
    test -f /usr/sbin/sshd && echo "✅ sshd found" && \
    test -f /root/.ssh/id_rsa && echo "✅ SSH keys generated"

# 5. Final build summary
RUN echo "========================================" && \
    echo "✅ BUILD COMPLETE - CUDA ${REQUIRED_CUDA_MAJOR} ENFORCED" && \
    echo "========================================" && \
    echo "" && \
    echo "CUDA Configuration:" && \
    echo "  Required CUDA:   ${REQUIRED_CUDA_MAJOR}.${REQUIRED_CUDA_MINOR}+" && \
    echo "  Min Driver:      ${MIN_DRIVER_VERSION}+" && \
    echo "  CUDA Home:       ${CUDA_HOME}" && \
    echo "" && \
    nvcc --version | grep release && \
    echo "" && \
    echo "FlashInfer Status:" && \
    python3 -c "import importlib.metadata as im; print(f'  Installed: {im.version(\"flashinfer-python\")}')" 2>/dev/null || \
    echo "  Not installed (TRT-LLM will use default attention)" && \
    echo "" && \
    echo "Runtime checks will verify driver compatibility."

##############################
# Cleanup
##############################
RUN python3 -m pip cache purge && \
    rm -rf /root/.cache/pip /tmp/* /var/tmp/* && \
    find ${PYTHON_SITE_PACKAGES} -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true



WORKDIR /workspace
CMD ["/bin/bash"]