apiVersion: kubeflow.org/v2beta1
kind: MPIJob
metadata:
  name: nccl-test-dynamo-h100
  namespace: default
spec:
  runPolicy:
    cleanPodPolicy: Running
    backoffLimit: 5
  slotsPerWorker: 8
  mpiReplicaSpecs:
    Launcher:
      replicas: 1
      template:
        spec:
          restartPolicy: Never
          containers:
          - image: public.ecr.aws/v9l4g5s4/aws-efa-dynamo-h100:v3
            imagePullPolicy: Always
            name: nccl-launcher
            command:
            - /bin/bash
            - -c
            - |
              echo "=========================================="
              echo "Starting NCCL Test with Dynamo H100 Image"
              echo "=========================================="
              echo "Date: $(date)"
              echo "Hostname: $(hostname)"
              echo ""

              # Display environment info
              echo "Environment Configuration:"
              echo "- NCCL Version: $(ls /opt/nccl*/lib/libnccl.so.* 2>/dev/null | head -1 | sed 's/.*libnccl.so.//')"
              echo "- MPI_HOME: $MPI_HOME"
              echo "- OFI_NCCL Plugin: $(ls /opt/aws-ofi-nccl*/lib/*.so 2>/dev/null | head -1)"
              echo "- EFA Devices: $(ls /sys/class/infiniband/ 2>/dev/null || echo 'None detected')"
              echo "- CUDA Architecture: SM90 (H100)"
              echo ""

              echo "Waiting for workers to be ready..."
              sleep 20

              # Set EFA environment variables for H100
              export FI_PROVIDER=efa
              export FI_EFA_USE_DEVICE_RDMA=1
              export NCCL_PROTO=Simple
              export NCCL_SOCKET_IFNAME=eth0
              export NCCL_DEBUG=INFO
              export NCCL_ALGO=Ring
              export NCCL_MIN_NCHANNELS=8

              echo "Running NCCL AllReduce test on 8 H100 GPUs..."
              export PATH="/opt/amazon/openmpi/bin:$PATH"
              /opt/amazon/openmpi/bin/mpirun -np 8 --allow-run-as-root \
                --bind-to none \
                --map-by slot \
                --mca pml ob1 \
                --mca btl tcp,self \
                --mca btl_tcp_if_include eth0 \
                -x LD_LIBRARY_PATH \
                -x FI_PROVIDER \
                -x FI_EFA_USE_DEVICE_RDMA \
                -x NCCL_PROTO \
                -x NCCL_SOCKET_IFNAME \
                -x NCCL_DEBUG \
                -x NCCL_ALGO \
                -x NCCL_MIN_NCHANNELS \
                /opt/nccl-tests/build/all_reduce_perf \
                  -b 8M -e 1G -f 2 -g 1 -c 1 -n 20

              echo ""
              echo "=========================================="
              echo "NCCL Test Complete!"
              echo "=========================================="
            resources:
              requests:
                memory: "16Gi"
                cpu: "4"
              limits:
                memory: "16Gi"
                cpu: "4"
    Worker:
      replicas: 1
      template:
        spec:
          containers:
          - image: public.ecr.aws/v9l4g5s4/aws-efa-dynamo-h100:v3
            imagePullPolicy: Always
            name: nccl-worker
            env:
            - name: FI_PROVIDER
              value: "efa"
            - name: FI_EFA_USE_DEVICE_RDMA
              value: "1"
            - name: NCCL_PROTO
              value: "Simple"
            - name: NCCL_SOCKET_IFNAME
              value: "eth0"
            - name: NCCL_DEBUG
              value: "INFO"
            - name: NCCL_ALGO
              value: "Ring"
            - name: NCCL_MIN_NCHANNELS
              value: "8"
            resources:
              requests:
                nvidia.com/gpu: 8
                hugepages-2Mi: 5120Mi
                vpc.amazonaws.com/efa: 1
                memory: "256Gi"
                cpu: "94"
              limits:
                nvidia.com/gpu: 8
                hugepages-2Mi: 5120Mi
                vpc.amazonaws.com/efa: 1
                memory: "256Gi"
                cpu: "94"
          nodeSelector:
            node.kubernetes.io/instance-type: "ml.p5.48xlarge"
          tolerations:
          - key: nvidia.com/gpu
            operator: Exists
            effect: NoSchedule