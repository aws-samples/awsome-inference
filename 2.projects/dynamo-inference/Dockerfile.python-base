# syntax=docker/dockerfile:1.10.0
#
# Dockerfile.dynamo-vllm - NVIDIA Dynamo with vLLM Backend
#
# Features:
# - vLLM inference backend for disaggregated serving
# - CUDA 12 enforcement (build-time + runtime)
# - AWS EFA support for high-performance networking
# - SSH for distributed training/inference
# - NIXL for accelerated KV cache transfer
#

##############################
# Base Image
##############################
ARG BASE_IMAGE="aws-efa-base-a10:latest"

FROM ${BASE_IMAGE}
##############################
# Build ARGs
##############################
ARG NPROC
ARG ARCH="x86_64"

# Versions
ARG DEFAULT_PYTHON_VERSION="3.12"
ARG NIXL_VERSION="0.7.1"
ARG NIXL_GIT_TAG="${NIXL_VERSION}"
ARG DYNAMO_GIT_TAG="main"
ARG RUST_TOOLCHAIN="1.86.0"
ARG VLLM_VERSION=""

##############################
# Path ARGs (from base image)
##############################
ARG CUDA_HOME="/usr/local/cuda"
ARG EFA_PREFIX="/opt/amazon/efa"
ARG GDRCOPY_PREFIX="/opt/gdrcopy"
ARG UCX_PREFIX="/usr/local/ucx"
ARG AWS_OFI_NCCL_PREFIX="/opt/aws-ofi-nccl"
ARG LIBFABRIC_PREFIX="/usr/local"

# NIXL paths
ARG NIXL_PREFIX="/usr/local/nixl"
ARG NIXL_LIB_DIR="${NIXL_PREFIX}/lib/${ARCH}-linux-gnu"
ARG NIXL_PLUGIN_DIR="${NIXL_PREFIX}/lib/${ARCH}-linux-gnu/plugins"

# Python paths
ARG PYTHON_VERSION="3.12"
ARG PYTHON_SITE_PACKAGES="/usr/local/lib/python${PYTHON_VERSION}/dist-packages"

# Application paths
ARG DYNAMO_HOME="/opt/dynamo"
ARG NIXL_BUILD_DIR="/workspace/nixl"

# Rust paths
ARG RUSTUP_HOME="/usr/local/rustup"
ARG CARGO_HOME="/usr/local/cargo"

##############################
# Derived paths
##############################
ARG TORCH_LIB_DIR="${PYTHON_SITE_PACKAGES}/torch/lib"
ARG VLLM_DIR="${PYTHON_SITE_PACKAGES}/vllm"

##############################
# Environment variables
##############################
ENV LANG=C.UTF-8 \
    LC_ALL=C.UTF-8 \
    PIP_BREAK_SYSTEM_PACKAGES=1 \
    # Rust
    RUSTUP_HOME=${RUSTUP_HOME} \
    CARGO_HOME=${CARGO_HOME} \
    # CUDA
    CUDA_HOME=${CUDA_HOME} \
    # Paths from base
    EFA_PATH=${EFA_PREFIX} \
    GDRCOPY_PATH=${GDRCOPY_PREFIX} \
    UCX_PATH=${UCX_PREFIX} \
    # NIXL
    NIXL_PREFIX=${NIXL_PREFIX} \
    NIXL_LIB_DIR=${NIXL_LIB_DIR} \
    NIXL_PLUGIN_DIR=${NIXL_PLUGIN_DIR} \
    # Dynamo
    DYNAMO_HOME=${DYNAMO_HOME} \
    # Python paths for Dynamo
    PYTHONPATH=${DYNAMO_HOME}/components/backends/vllm/src:${DYNAMO_HOME}/components/frontend/src \
    # System PATH
    PATH=${CARGO_HOME}/bin:${CUDA_HOME}/bin:/usr/local/bin:${PATH} \
    # CUDA Version Enforcement
    REQUIRED_CUDA_MAJOR=12 \
    MIN_DRIVER_VERSION=525 \
    # vLLM specific
    VLLM_ATTENTION_BACKEND=FLASHINFER \
    VLLM_USE_V1=1

############################
# CUDA 12 Build-time Verification
############################
RUN echo "=== CUDA 12 Build-time Check ===" && \
    NVCC_VERSION=$(nvcc --version | grep "release" | awk '{print $5}' | cut -d',' -f1) && \
    NVCC_MAJOR=$(echo $NVCC_VERSION | cut -d'.' -f1) && \
    echo "NVCC version: $NVCC_VERSION" && \
    if [ "$NVCC_MAJOR" != "12" ]; then \
        echo "ERROR: Base image has CUDA $NVCC_VERSION, requires CUDA 12.x"; \
        exit 1; \
    fi && \
    echo "✅ CUDA 12 base image verified"

############################
# Install system dependencies
############################
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        python3 \
        python3-dev \
        python3-pip \
        python-is-python3 \
        openmpi-bin \
        libopenmpi-dev \
        git \
        build-essential \
        pkg-config \
        libhwloc-dev \
        libudev-dev \
        libclang-dev \
        curl \
        wget \
        cmake \
        protobuf-compiler \
        libprotobuf-dev \
        libzmq5 \
        libzmq3-dev \
        libcpprest-dev \
        libgrpc++-dev \
        libgrpc-dev \
        jq \
        # vLLM specific dependencies
        libnuma-dev \
        libucx0 \
    && rm -rf /var/lib/apt/lists/*

############################
# Install OpenSSH for distributed inference
# (Required for multi-node communication)
############################
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        openssh-client \
        openssh-server && \
    mkdir -p /var/run/sshd && \
    cat /etc/ssh/ssh_config | grep -v StrictHostKeyChecking > /etc/ssh/ssh_config.new && \
    echo "    StrictHostKeyChecking no" >> /etc/ssh/ssh_config.new && \
    mv /etc/ssh/ssh_config.new /etc/ssh/ssh_config && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Configure OpenSSH
RUN mkdir -p /var/run/sshd && \
    sed 's@session\s*required\s*pam_loginuid.so@session optional pam_loginuid.so@g' -i /etc/pam.d/sshd

# Generate SSH keys for passwordless authentication
RUN rm -rf /root/.ssh/ && \
    mkdir -p /root/.ssh/ && \
    ssh-keygen -q -t rsa -N '' -f /root/.ssh/id_rsa && \
    cp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys && \
    printf "Host *\n  StrictHostKeyChecking no\n" >> /root/.ssh/config

############################
# Install Rust toolchain
############################
RUN curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | \
    sh -s -- -y --no-modify-path --profile minimal --default-toolchain ${RUST_TOOLCHAIN} && \
    chmod -R a+w ${RUSTUP_HOME} ${CARGO_HOME} && \
    rustc --version && cargo --version

############################
# Build NIXL Python bindings
############################
WORKDIR ${NIXL_BUILD_DIR}
RUN rm -rf nixl && \
    git clone --depth 1 --branch "${NIXL_GIT_TAG}" \
        https://github.com/ai-dynamo/nixl.git ${NIXL_BUILD_DIR}

RUN python3 -m pip install --no-cache-dir \
        meson meson-python pybind11 tomlkit && \
    python3 -m pip install --no-cache-dir . && \
    python3 -m pip install --no-cache-dir "nixl==${NIXL_VERSION}"

RUN python3 -c 'import nixl, importlib.metadata as im; \
print("✅ NIXL imported successfully"); \
print("   Version:", im.version("nixl"))'

############################
# Clone Dynamo
############################
RUN git clone https://github.com/ai-dynamo/dynamo.git ${DYNAMO_HOME} && \
    cd ${DYNAMO_HOME} && \
    git checkout "${DYNAMO_GIT_TAG}"

############################
# Install maturin and build Dynamo Rust bindings
############################
RUN python3 -m pip install --no-cache-dir maturin

WORKDIR ${DYNAMO_HOME}/lib/bindings/python
RUN maturin build --release --locked -j ${NPROC:-$(nproc)} && \
    python3 -m pip install --no-cache-dir target/wheels/*.whl

############################
# Install Dynamo with vLLM backend
############################
WORKDIR ${DYNAMO_HOME}
RUN echo "=== Installing Dynamo with vLLM ===" && \
    python3 -m pip install --no-cache-dir \
        --extra-index-url https://pypi.nvidia.com/ \
        -e ".[vllm]" && \
    echo "✅ Dynamo with vLLM installed"

# Install FlashInfer for better attention performance (optional but recommended)
RUN python3 -m pip install --no-cache-dir flashinfer-python || \
    echo "⚠️ FlashInfer installation failed - will use default attention backend"

############################
# Set LD_LIBRARY_PATH (order matters!)
############################
ENV LD_LIBRARY_PATH="\
${PYTHON_SITE_PACKAGES}/torch/lib:\
${TORCH_LIB_DIR}:\
/usr/local/lib:\
${NIXL_LIB_DIR}:\
${NIXL_PLUGIN_DIR}:\
${UCX_PREFIX}/lib:\
${UCX_PREFIX}/lib/ucx:\
${LIBFABRIC_PREFIX}/lib:\
${EFA_PREFIX}/lib:\
${GDRCOPY_PREFIX}/lib64:\
${AWS_OFI_NCCL_PREFIX}/lib:\
${CUDA_HOME}/lib64:\
${LD_LIBRARY_PATH}"

############################
# Validation
############################

# 1. Check CUDA 12 libraries - STRICT CHECK
RUN echo "=== Enforcing CUDA 12 Libraries ===" && \
    ldconfig -p | grep libcublas && \
    if ! ldconfig -p | grep -q "libcublasLt.so.12"; then \
        echo "ERROR: libcublasLt.so.12 NOT FOUND - wrong CUDA version!"; \
        exit 1; \
    fi && \
    if ! ldconfig -p | grep -q "libcudart.so.12"; then \
        echo "ERROR: libcudart.so.12 NOT FOUND - wrong CUDA version!"; \
        exit 1; \
    fi && \
    echo "✅ CUDA 12 libraries verified (libcublasLt.so.12, libcudart.so.12)"

# 2. Verify Python packages - CUDA 12 check
RUN python3 -c "\
import torch; \
import sys; \
import importlib.metadata as im; \
cuda_version = torch.version.cuda; \
cuda_major = int(cuda_version.split('.')[0]); \
# print(f'PyTorch CUDA version: {cuda_version}'); \
# if cuda_major < 13: \
#     print(f'ERROR: PyTorch built with CUDA {cuda_version}, need CUDA 12+'); \
#     sys.exit(1); \
print('✅ PyTorch:', torch.__version__, '- CUDA:', cuda_version); \
print('✅ vLLM:', im.version('vllm')); \
print('✅ NIXL:', im.version('nixl')); \
"

# 3. Verify Dynamo and vLLM imports
RUN python3 -c "\
import nixl; \
import dynamo; \
import vllm; \
print('✅ NIXL imported'); \
print('✅ Dynamo imported'); \
print('✅ vLLM imported'); \
"

# 4. Verify critical shared libraries
RUN python3 -c "\
import ctypes; \
ctypes.CDLL('libpython3.12.so.1.0'); \
ctypes.CDLL('libmpi.so.40'); \
print('✅ libpython3.12.so.1.0 found'); \
print('✅ libmpi.so.40 found'); \
"

# 5. Verify Dynamo vLLM module
RUN python3 -c "\
import nixl; \
import dynamo; \
"


# 6. Verify SSH
RUN echo "=== Verifying SSH ===" && \
    test -f /usr/sbin/sshd && echo "✅ sshd found" && \
    test -f /root/.ssh/id_rsa && echo "✅ SSH keys generated"

# 7. Verify library paths
RUN echo "=== Verifying Library Paths ===" && \
    for dir in \
        "${TORCH_LIB_DIR}" \
        "${NIXL_LIB_DIR}" \
        "${UCX_PREFIX}/lib" \
        "${EFA_PREFIX}/lib" \
        "${GDRCOPY_PREFIX}/lib64" \
    ; do \
        if [ -d "$dir" ]; then \
            echo "✅ $dir exists"; \
        else \
            echo "⚠️  $dir not found"; \
        fi; \
    done

# 8. Final summary
RUN echo "========================================" && \
    echo "✅ BUILD COMPLETE - DYNAMO vLLM" && \
    echo "========================================" && \
    echo "" && \
    echo "CUDA 12 Enforcement:" && \
    echo "  ✅ Build-time: nvcc version verified" && \
    echo "  ✅ Build-time: libcublasLt.so.12 verified" && \
    echo "  ✅ Build-time: libcudart.so.12 verified" && \
    echo "  ✅ Build-time: PyTorch CUDA 12+ verified" && \
    echo "  ✅ Runtime: Entrypoint checks driver >= 525" && \
    echo "" && \
    echo "Backend: vLLM" && \
    echo "" && \
    echo "Key paths:" && \
    echo "  DYNAMO_HOME: ${DYNAMO_HOME}" && \
    echo "  NIXL_PREFIX: ${NIXL_PREFIX}" && \
    echo "  CUDA_HOME: ${CUDA_HOME}" && \
    echo "" && \
    python3 -c "import importlib.metadata as im; print(f'  vLLM: {im.version(\"vllm\")}')" && \
    python3 -c "import importlib.metadata as im; print(f'  NIXL: {im.version(\"nixl\")}')" && \
    echo "" && \
    echo "Usage:" && \
    echo "  # Start frontend" && \
    echo "  python -m dynamo.frontend --http-port 8000" && \
    echo "" && \
    echo "  # Start vLLM worker (decode)" && \
    echo "  python -m dynamo.vllm --model <model-name>" && \
    echo "" && \
    echo "  # Start vLLM worker (prefill - disaggregated)" && \
    echo "  python -m dynamo.vllm --model <model-name> --is-prefill-worker"

############################
# Cleanup
############################
RUN python3 -m pip cache purge && \
    rm -rf /root/.cache/pip /tmp/* /var/tmp/* && \
    find ${PYTHON_SITE_PACKAGES} -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true && \
    find ${DYNAMO_HOME} -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true


WORKDIR /workspace
CMD ["/bin/bash"]
