# syntax=docker/dockerfile:1.10.0
#
# Dockerfile.base.cuda128 - Unified CUDA 12.8 EFA/NIXL Base Image
# ================================================================
# Common base for both vLLM and TRT-LLM backends
#
# Stack: CUDA 12.8.1 based on NGC pytorch:25.03-py3 (HPC-X removed)
#
# Features:
# - CUDA 12.8.1 (DeepGEMM compatible)
# - PyTorch 2.7.0a0 from NGC
# - AWS EFA + libfabric v2.3.0
# - UCX v1.19.0 with EFA + GDRCopy (custom built, no HPC-X)
# - OpenMPI from EFA installer (custom built, no HPC-X)
# - NCCL 2.25+ with aws-ofi-nccl
# - NIXL 0.7.1 (C++ + Python)
# - GDRCopy 2.4.1
# - Rust toolchain for Dynamo
#
# Target: p5.48xlarge (H100 x 8, EFA x 32)
# Driver: 550.163.01 (forward compat to CUDA 12.8)
#

##############################
# Stage 1: Build Stage
##############################
FROM nvcr.io/nvidia/pytorch:25.03-py3 AS build

ARG ARCH="x86_64"
ARG NPROC="48"

############################
# Remove HPC-X to avoid conflicts with custom-built UCX/MPI
############################
RUN echo "=== Removing HPC-X from base image ===" && \
    # Remove HPC-X packages if installed via apt
    apt-get update && \
    apt-get remove -y hpcx libhpcx* hpcx-* 2>/dev/null || true && \
    apt-get autoremove -y && \
    apt-get clean && \
    # Remove HPC-X directories
    rm -rf /opt/hpcx \
           /usr/local/hpcx \
           /opt/mellanox/hpcx && \
    # Unset HPC-X environment variables in system profile
    sed -i '/HPCX/d' /etc/profile.d/* 2>/dev/null || true && \
    sed -i '/hpcx/d' /etc/environment 2>/dev/null || true && \
    rm -rf /var/lib/apt/lists/* && \
    echo "HPC-X removed successfully"

# Unset HPC-X environment variables for build
ENV HPCX_DIR="" \
    HPCX_HOME="" \
    HPCX_UCX_DIR="" \
    HPCX_SHARP_DIR="" \
    HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR="" \
    HPCX_CLUSTERKIT_DIR="" \
    HPCX_MPI_DIR="" \
    HPCX_OSHMEM_DIR="" \
    HPCX_MPI_TESTS_DIR="" \
    HPCX_OSU_DIR="" \
    HPCX_IPM_DIR=""

# Core versions
ARG NIXL_VERSION="0.7.1"
ARG NIXL_GIT_TAG="${NIXL_VERSION}"
ARG UCX_VERSION="v1.19.0"
ARG LIBFABRIC_VERSION="v2.3.0"
ARG LIBFABRIC_INSTALL_PATH="/usr/local"
ARG GDRCOPY_VERSION="2.4.1"
ARG AWS_OFI_NCCL_VERSION="v1.17.1"
ARG AWS_SDK_VERSION="1.11.581"
ARG ETCD_CPP_VERSION="0.15.4"
ARG RDMA_CORE_VERSION="v51.0"
ARG EFA_INSTALLER_VERSION="1.43.1"
ARG CUDA_ARCH="86"
ARG NCCL_TESTS_VERSION="v2.16.9"

# Rust toolchain
ARG RUSTUP_VERSION="1.28.1"
ARG RUST_TOOLCHAIN="1.86.0"

ENV DEBIAN_FRONTEND=noninteractive \
    LANG=C.UTF-8 \
    LC_ALL=C.UTF-8 \
    CUDA_HOME=/usr/local/cuda \
    PATH=/usr/local/cuda/bin:/usr/local/bin:${PATH}

WORKDIR /opt/build

############################
# Verify CUDA 12.8 environment
############################
# RUN echo "=== CUDA 12.8 Build Environment Verification ===" && \
#     nvcc --version && \
#     NVCC_VERSION=$(nvcc --version | grep "release" | awk '{print $5}' | cut -d',' -f1) && \
#     NVCC_MAJOR=$(echo $NVCC_VERSION | cut -d'.' -f1) && \
#     NVCC_MINOR=$(echo $NVCC_VERSION | cut -d'.' -f2) && \
#     echo "CUDA Toolkit: $NVCC_VERSION" && \
#     if [ "$NVCC_MAJOR" != "12" ] || [ "$NVCC_MINOR" -lt "8" ]; then \
#         echo "ERROR: Requires CUDA 12.8+, got CUDA $NVCC_VERSION"; \
#         exit 1; \
#     fi && \
#     echo "CUDA 12.8+ verified ($NVCC_VERSION)" && \
#     python3 -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.version.cuda}')"

############################
# 1. System build toolchain
############################
RUN apt-get update -y && \
    apt-get install -y --no-install-recommends \
        build-essential \
        gcc \
        autoconf \
        automake \
        libtool \
        cmake \
        ninja-build \
        meson \
        pkg-config \
        git \
        wget \
        curl \
        ca-certificates \
        apt-utils \
        vim \
        jq \
        pandoc \
        gdb \
        kmod \
        libibverbs-dev \
        rdma-core \
        ibverbs-utils \
        libibumad-dev \
        librdmacm-dev \
        libnuma-dev \
        hwloc \
        libhwloc-dev \
        libssl-dev \
        zlib1g-dev \
        libcurl4-openssl-dev \
        libprotobuf-dev \
        protobuf-compiler \
        protobuf-compiler-grpc \
        libgrpc++-dev \
        libgrpc-dev \
        libaio-dev \
        liburing-dev \
        check \
        libsubunit-dev \
        debhelper \
        devscripts \
        openssh-client \
        openssh-server \
        pybind11-dev \
        libgflags-dev \
        clang \
        libclang-dev \
    && rm -rf /var/lib/apt/lists/*

############################
# 2. RDMA core
############################
RUN cd /opt/build && \
    wget https://github.com/linux-rdma/rdma-core/archive/refs/tags/${RDMA_CORE_VERSION}.tar.gz && \
    tar xzf ${RDMA_CORE_VERSION}.tar.gz && \
    cd rdma-core-* && \
    mkdir build && cd build && \
    cmake -DCMAKE_INSTALL_PREFIX=/usr/local \
          -DNO_PYVERBS=1 \
          -DNO_MAN_PAGES=1 \
          -DENABLE_STATIC=1 \
          .. && \
    make -j${NPROC:-$(nproc)} && make install && \
    ldconfig && \
    cd / && rm -rf /opt/build/rdma-core-*

############################
# 3. EFA userspace (no kmod)
############################
RUN apt-get update && apt-get install -y --no-install-recommends \
    pciutils \
    environment-modules \
    tcl \
    libevent-core-2.1-7t64 \
    libevent-pthreads-2.1-7t64 \
    && rm -rf /var/lib/apt/lists/*

RUN cd /tmp && \
    echo "=== Installing EFA Installer ===" && \
    curl -O https://efa-installer.amazonaws.com/aws-efa-installer-${EFA_INSTALLER_VERSION}.tar.gz && \
    tar -xf aws-efa-installer-${EFA_INSTALLER_VERSION}.tar.gz && \
    cd aws-efa-installer && \
    ./efa_installer.sh -y --skip-kmod --skip-limit-conf --enable-gdr --no-verify && \
    cd .. && rm -rf aws-efa-installer* && \
    echo "EFA installed to /opt/amazon/efa"

ENV EFA_INSTALLER_PATH=/opt/amazon/efa \
    OPENMPI_PATH=/opt/amazon/openmpi \
    PATH=/opt/amazon/openmpi/bin:/opt/amazon/efa/bin:${PATH} \
    LD_LIBRARY_PATH=/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:${LD_LIBRARY_PATH}

# Set up EFA library paths
RUN mkdir -p /opt/amazon/efa/lib /opt/amazon/efa/include && \
    if [ -f /usr/lib/x86_64-linux-gnu/libefa.so ]; then \
        ln -sf /usr/lib/x86_64-linux-gnu/libefa.so* /opt/amazon/efa/lib/ && \
        echo "EFA library symlinked"; \
    fi && \
    if [ -d /usr/include/infiniband ]; then \
        ln -sfn /usr/include/infiniband /opt/amazon/efa/include/infiniband; \
    fi && \
    if [ -d /usr/include/rdma ]; then \
        ln -sfn /usr/include/rdma /opt/amazon/efa/include/rdma; \
    fi

ENV MPI_HOME=/opt/amazon/openmpi \
    C_INCLUDE_PATH=/opt/amazon/openmpi/include:${CUDA_HOME}/include \
    CPLUS_INCLUDE_PATH=/opt/amazon/openmpi/include:${CUDA_HOME}/include \
    CPATH=/opt/amazon/openmpi/include:${CUDA_HOME}/include \
    LIBRARY_PATH=/opt/amazon/openmpi/lib:${CUDA_HOME}/lib64

############################
# 4. GDRCopy
############################
RUN git clone --depth 1 --branch v${GDRCOPY_VERSION} https://github.com/NVIDIA/gdrcopy.git && \
    cd gdrcopy && \
    CUDA=${CUDA_HOME} make prefix=/opt/gdrcopy lib lib_install && \
    echo "/opt/gdrcopy/lib64" > /etc/ld.so.conf.d/gdrcopy.conf && \
    ldconfig && \
    cd / && rm -rf gdrcopy

ENV GDRCOPY_PATH=/opt/gdrcopy

############################
# 5. libfabric v2.3.0
############################
RUN cd /opt/build && \
    wget --tries=3 --waitretry=5 \
      "https://github.com/ofiwg/libfabric/releases/download/${LIBFABRIC_VERSION}/libfabric-${LIBFABRIC_VERSION#v}.tar.bz2" \
      -O libfabric.tar.bz2 && \
    tar xjf libfabric.tar.bz2 && rm libfabric.tar.bz2 && \
    cd libfabric-* && \
    ./configure \
      --prefix=${LIBFABRIC_INSTALL_PATH} \
      --disable-verbs \
      --disable-psm3 \
      --disable-opx \
      --disable-usnic \
      --disable-rstream \
      --enable-efa \
      --with-cuda=${CUDA_HOME} \
      --enable-cuda-dlopen \
      --with-gdrcopy=${GDRCOPY_PATH} \
      --enable-gdrcopy-dlopen && \
    make -j${NPROC:-$(nproc)} && make install && \
    echo "${LIBFABRIC_INSTALL_PATH}/lib" > /etc/ld.so.conf.d/libfabric.conf && \
    ldconfig && \
    cd / && rm -rf /opt/build/libfabric-*

############################
# 6. UCX v1.19 with EFA+GDRCopy
############################


RUN echo "=== Removing any existing UCX installation ===" && \
    # Remove UCX packages
    apt-get update && \
    apt-get remove -y ucx libucx* 2>/dev/null || true && \
    apt-get autoremove -y && \
    apt-get clean && \
    # Remove UCX directories
    rm -rf /usr/local/ucx \
           /opt/ucx \
           /usr/lib/x86_64-linux-gnu/libucx* \
           /usr/lib/x86_64-linux-gnu/libucp* \
           /usr/lib/x86_64-linux-gnu/libuct* \
           /usr/lib/x86_64-linux-gnu/libucs* \
           /usr/lib/x86_64-linux-gnu/ucx \
           /usr/include/ucx \
           /usr/include/ucp \
           /usr/include/uct \
           /usr/include/ucs && \
    # Clean ldconfig entries
    rm -f /etc/ld.so.conf.d/*ucx* && \
    ldconfig && \
    echo "✓ Existing UCX removed"

RUN cd /opt/build && \
    git clone https://github.com/openucx/ucx.git && \
    cd ucx && \
    git checkout ${UCX_VERSION} && \
    ./autogen.sh && \
    ./configure \
      --prefix=/usr/local/ucx \
      --enable-shared \
      --disable-static \
      --disable-doxygen-doc \
      --enable-optimizations \
      --enable-cma \
      --enable-devel-headers \
      --enable-mt \
      --with-cuda=${CUDA_HOME} \
      --with-gdrcopy=/opt/gdrcopy \
      --with-verbs=/opt/amazon/efa \
      --with-dm \
      --with-efa=/opt/amazon/efa && \
    make -j${NPROC:-$(nproc)} && make install-strip && \
    echo "/usr/local/ucx/lib" > /etc/ld.so.conf.d/ucx.conf && \
    echo "/usr/local/ucx/lib/ucx" >> /etc/ld.so.conf.d/ucx.conf && \
    ldconfig && \
    cd / && rm -rf /opt/build/ucx

ENV UCX_PATH=/usr/local/ucx

############################
# 7. Build NCCL-tests
############################
RUN git clone -b ${NCCL_TESTS_VERSION} https://github.com/NVIDIA/nccl-tests.git /opt/nccl-tests && \
    cd /opt/nccl-tests && \
    make -j $(nproc) \
        MPI=1 \
        MPI_HOME=/opt/amazon/openmpi \
        CUDA_HOME=${CUDA_HOME} \
        NCCL_HOME=/usr/local \
        NVCC_GENCODE="-gencode=arch=compute_${CUDA_ARCH},code=sm_${CUDA_ARCH}"

ENV NCCL_TESTS_PATH=/opt/nccl-tests

############################
# 8. SSH setup
############################
RUN mkdir -p /var/run/sshd \
    && ssh-keygen -A \
    && sed -i 's/PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config \
    && sed -i 's/#PermitUserEnvironment no/PermitUserEnvironment yes/' /etc/ssh/sshd_config \
    && echo "* soft memlock unlimited" >> /etc/security/limits.conf \
    && echo "* hard memlock unlimited" >> /etc/security/limits.conf

RUN sed -i 's/[ #]\(.*StrictHostKeyChecking \).*/\1no/g' /etc/ssh/ssh_config && \
    echo "UserKnownHostsFile /dev/null" >> /etc/ssh/ssh_config && \
    sed -i 's/#\(StrictModes \).*/\1no/g' /etc/ssh/sshd_config

############################
# 9. etcd-cpp-apiv3 + AWS SDK
############################
RUN apt-get update && apt-get install -y libcpprest-dev && rm -rf /var/lib/apt/lists/*

# Fix the utf8_range library path issue by creating symlinks
RUN mkdir -p /usr/lib && \
    if [ -f /usr/lib/x86_64-linux-gnu/libutf8_validity.a ]; then \
        ln -sf /usr/lib/x86_64-linux-gnu/libutf8_validity.a /usr/lib/libutf8_validity.a; \
    elif [ -f /usr/lib/x86_64-linux-gnu/libutf8_range.a ]; then \
        ln -sf /usr/lib/x86_64-linux-gnu/libutf8_range.a /usr/lib/libutf8_range.a; \
    fi && \
    ldconfig

# Install grpc and protobuf from source properly
RUN cd /tmp && \
    git clone --recurse-submodules -b v1.62.1 --depth 1 --shallow-submodules https://github.com/grpc/grpc && \
    cd grpc && \
    mkdir -p cmake/build && cd cmake/build && \
    cmake ../.. \
        -DgRPC_INSTALL=ON \
        -DgRPC_BUILD_TESTS=OFF \
        -DCMAKE_BUILD_TYPE=Release \
        -DCMAKE_INSTALL_PREFIX=/usr/local && \
    make -j${NPROC:-$(nproc)} && \
    make install && \
    cd / && rm -rf /tmp/grpc && \
    ldconfig

RUN git clone --depth 1 -b v${ETCD_CPP_VERSION} https://github.com/etcd-cpp-apiv3/etcd-cpp-apiv3.git && \
    cd etcd-cpp-apiv3 && \
    sed -i '/^find_dependency(cpprestsdk)$/d' etcd-cpp-api-config.in.cmake && \
    mkdir build && cd build && \
    cmake .. -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/usr/local \
        -DCMAKE_PREFIX_PATH=/usr/local && \
    make -j${NPROC:-$(nproc)} && make install && \
    cd / && rm -rf etcd-cpp-apiv3

ENV ETCD_CPP_API_DISABLE_URI_VALIDATION=1

RUN git clone --recurse-submodules --depth 1 --shallow-submodules \
        https://github.com/aws/aws-sdk-cpp.git --branch ${AWS_SDK_VERSION} && \
    mkdir aws_sdk_build && cd aws_sdk_build && \
    cmake ../aws-sdk-cpp/ \
        -DCMAKE_BUILD_TYPE=Release \
        -DBUILD_ONLY="s3" \
        -DENABLE_TESTING=OFF \
        -DCMAKE_INSTALL_PREFIX=/usr/local && \
    make -j${NPROC:-$(nproc)} && make install && \
    cd / && rm -rf aws-sdk-cpp aws_sdk_build && \
    ldconfig

############################
# 10. gusli
############################
RUN git clone https://github.com/nvidia/gusli.git && \
    cd gusli && \
    make all BUILD_RELEASE=1 BUILD_FOR_UNITEST=0 VERBOSE=1 ALLOW_USE_URING=0 && \
    cd .. && rm -rf gusli

############################
# 11. Rust toolchain
############################
ENV RUSTUP_HOME=/usr/local/rustup \
    CARGO_HOME=/usr/local/cargo \
    PATH=/usr/local/cargo/bin:$PATH \
    RUSTARCH=${ARCH}-unknown-linux-gnu

RUN cd /tmp && \
    wget -q "https://static.rust-lang.org/rustup/archive/${RUSTUP_VERSION}/${RUSTARCH}/rustup-init" && \
    chmod +x rustup-init && \
    ./rustup-init -y --no-modify-path --profile minimal --default-toolchain ${RUST_TOOLCHAIN} && \
    rm rustup-init && \
    chmod -R a+w ${RUSTUP_HOME} ${CARGO_HOME} && \
    rustup default ${RUST_TOOLCHAIN} && \
    rustc --version && cargo --version


############################
# 6b. UCC (master branch - compatible with UCX 1.19)
############################
RUN echo "=== Removing any existing UCC ===" && \
    apt-get update && \
    apt-get remove -y libucc* ucc 2>/dev/null || true && \
    apt-get autoremove -y && \
    rm -rf /usr/local/ucc /opt/ucc && \
    echo "✓ Old UCC removed"

RUN cd /opt/build && \
    echo "=== Building UCC from master (sm_${CUDA_ARCH} only) ===" && \
    git clone https://github.com/openucx/ucc.git && \
    cd ucc && \
    git checkout master && \
    ./autogen.sh && \
    NVCC_GENCODE="-gencode=arch=compute_${CUDA_ARCH},code=sm_${CUDA_ARCH}" \
    ./configure \
        --prefix=/usr/local/ucc \
        --with-ucx=${UCX_PATH} \
        --with-cuda=${CUDA_HOME} \
        --enable-gtest=no \
        --with-nvcc-gencode="-gencode arch=compute_${CUDA_ARCH},code=sm_${CUDA_ARCH}" && \
    make -j${NPROC:-$(nproc)} \
        NVCC_GENCODE="-gencode=arch=compute_${CUDA_ARCH},code=sm_${CUDA_ARCH}" && \
    make install && \
    echo "/usr/local/ucc/lib" > /etc/ld.so.conf.d/ucc.conf && \
    ldconfig && \
    cd / && rm -rf /opt/build/ucc && \
    echo "✓ UCC built for sm_${CUDA_ARCH} (H100)"

ENV UCC_PATH=/usr/local/ucc \
    LD_LIBRARY_PATH=/usr/local/ucc/lib:${LD_LIBRARY_PATH}
############################
# 12. NIXL C++ + Rust
############################
WORKDIR /workspace/nixl
RUN git clone --depth 1 --branch ${NIXL_GIT_TAG} \
    https://github.com/ai-dynamo/nixl.git /workspace/nixl

# Fix event_type compilation issue
RUN sed -i 's/<< event.event_type()/<< static_cast<int>(event.event_type())/' \
    src/core/nixl_listener.cpp && \
    sed -i 's/static_cast<int>(event.event_type()) == etcd::Event::EventType::DELETE_/event.event_type() == etcd::Event::EventType::DELETE_/' \
    src/core/nixl_listener.cpp

ENV NIXL_PREFIX=/usr/local/nixl \
    NIXL_LIB_DIR=/usr/local/nixl/lib/${ARCH}-linux-gnu \
    NIXL_PLUGIN_DIR=/usr/local/nixl/lib/${ARCH}-linux-gnu/plugins \
    LD_LIBRARY_PATH=/usr/local/lib:${LIBFABRIC_INSTALL_PATH}/lib:${LD_LIBRARY_PATH}

RUN rm -rf build && \
    mkdir build && \
    meson setup \
        -Dlibfabric_path=${LIBFABRIC_INSTALL_PATH} \
        -Ducx_path=/usr/local/ucx \
        build/ \
        --prefix=${NIXL_PREFIX} && \
    cd build && \
    ninja -j${NPROC:-$(nproc)} && \
    ninja install && \
    echo "NIXL C++ built"

RUN echo "${NIXL_LIB_DIR}" > /etc/ld.so.conf.d/nixl.conf && \
    echo "${NIXL_PLUGIN_DIR}" >> /etc/ld.so.conf.d/nixl.conf && \
    ldconfig

ENV LIBCLANG_PATH=/usr/lib/llvm-18/lib

RUN cd src/bindings/rust && \
    cargo build --release --locked && \
    echo "NIXL Rust bindings built"

############################
# 12b. NIXL Python Bindings
############################
# Install NIXL Python bindings to site-packages
# Step 1: Install nixl-cu12 with libfabric and UCX paths
RUN cd /workspace/nixl && \
    echo "Installing NIXL Python bindings with:" && \
    echo "  - libfabric: ${LIBFABRIC_INSTALL_PATH}" && \
    echo "  - UCX: ${UCX_PATH}" && \
    pip install --no-cache-dir . \
        --config-settings=setup-args="-Dlibfabric_path=${LIBFABRIC_INSTALL_PATH} -Ducx_path=${UCX_PATH}" && \
    python3 -c "import nixl_cu12; print('✓ nixl-cu12 installed successfully')" && \
    python3 -c "import nixl_cu12; print(f'Location: {nixl_cu12.__file__}')"

# Step 2: Install the nixl meta-package (wrapper that provides 'import nixl')
RUN cd /workspace/nixl/src/bindings/python/nixl-meta && \
    # Generate proper pyproject.toml from template
    sed "s/@VERSION@/0.7.1/g; s/@WHEEL_DEP@/nixl-cu12/g" pyproject.toml.in > pyproject.toml && \
    # Copy LICENSE from root
    cp /workspace/nixl/LICENSE . && \
    pip install --no-cache-dir . && \
    python3 -c "import nixl; print('NIXL Python bindings installed successfully')" && \
    echo "NIXL module location:" && \
    python3 -c "import nixl; print(nixl.__file__)"

############################
# 13. nixlbench
############################
RUN echo "=== Building nixlbench ===" && \
    cd /workspace/nixl/benchmark/nixlbench && \
    rm -rf build && mkdir build && \
    meson setup build/ \
        --prefix=/usr/local \
        -Dnixl_path=${NIXL_PREFIX} \
        -Dcudapath_inc=/usr/local/cuda/include \
        -Dcudapath_lib=/usr/local/cuda/lib64 \
        -Detcd_inc_path=/usr/local/include \
        -Detcd_lib_path=/usr/local/lib && \
    cd build && \
    ninja -j${NPROC:-$(nproc)} && \
    ninja install && \
    echo "nixlbench installed"

############################
# 14. aws-ofi-nccl
############################
ARG NCCL_VERSION="2.27.7-1"
RUN echo "=== Building NCCL v${NCCL_VERSION} for SM${CUDA_ARCH} ===" && \
        cd /tmp && \
        git clone --depth 1 --branch v${NCCL_VERSION} https://github.com/NVIDIA/nccl.git && \
        cd nccl && \
        make -j${NPROC:-$(nproc)} src.build \
            CUDA_HOME=${CUDA_HOME} \
            NVCC_GENCODE="-gencode=arch=compute_${CUDA_ARCH},code=sm_${CUDA_ARCH}" && \
        make install PREFIX=/usr/local -j ${NPROC:-$(nproc)} && \
        echo "/usr/local/lib" > /etc/ld.so.conf.d/nccl.conf && \
        ldconfig && \
        echo "NCCL ${NCCL_VERSION} installed"; \
        cd / && rm -rf /tmp/nccl;

RUN cd /opt/build && \
    echo "=== Building aws-ofi-nccl ${AWS_OFI_NCCL_VERSION} ===" && \
    git clone --depth 1 --branch ${AWS_OFI_NCCL_VERSION} https://github.com/aws/aws-ofi-nccl.git aws-ofi-nccl && \
    cd aws-ofi-nccl && \
    ./autogen.sh && \
    ./configure \
        --prefix=/opt/aws-ofi-nccl \
        --with-libfabric=/usr/local \
        --with-cuda=${CUDA_HOME} && \
    make -j${NPROC:-$(nproc)} && \
    make install && \
    echo "/opt/aws-ofi-nccl/lib" > /etc/ld.so.conf.d/aws-ofi-nccl.conf && \
    ldconfig && \
    cd / && rm -rf /opt/build/aws-ofi-nccl*

##############################
# Stage 2: Runtime Image
##############################
FROM nvcr.io/nvidia/pytorch:25.03-py3 AS runtime

ARG ARCH="x86_64"


############################
# Step 1: Clean ALL conflicting paths first
############################
RUN echo "=== Cleaning runtime base image ===" && \
    apt-get update && \
    apt-get remove -y hpcx* libhpcx* ucx* libucx* ucc* libucc* 2>/dev/null || true && \
    apt-get autoremove -y && \
    apt-get clean && \
    # Remove ALL potentially conflicting paths
    rm -rf \
        /opt/hpcx \
        /usr/local/hpcx \
        /opt/mellanox/hpcx \
        /usr/local/ucx \
        /usr/local/ucc \
        /usr/local/nixl \
        /opt/ucx \
        /opt/ucc \
        /opt/amazon/openmpi \
        /opt/amazon/efa \
        /opt/gdrcopy \
        /opt/aws-ofi-nccl && \
    # Clean ldconfig
    rm -f /etc/ld.so.conf.d/*hpcx* \
          /etc/ld.so.conf.d/*ucx* \
          /etc/ld.so.conf.d/*ucc* \
          /etc/ld.so.conf.d/*nixl* && \
    ldconfig && \
    rm -rf /var/lib/apt/lists/* && \
    echo "✓ Runtime image cleaned"


############################
# Set environment variables (custom UCX/MPI priority)
############################
ENV LANG=C.UTF-8 \
    LC_ALL=C.UTF-8 \
    CUDA_HOME=/usr/local/cuda \
    HPCX_DIR="" \
    HPCX_HOME="" \
    HPCX_UCX_DIR="" \
    EFA_PATH=/opt/amazon/efa \
    GDRCOPY_PATH=/opt/gdrcopy \
    UCX_PATH=/usr/local/ucx \
    UCC_PATH=/usr/local/ucc \
    MPI_HOME=/opt/amazon/openmpi \
    NIXL_PREFIX=/usr/local/nixl \
    NIXL_LIB_DIR=/usr/local/nixl/lib/${ARCH}-linux-gnu \
    NIXL_PLUGIN_DIR=/usr/local/nixl/lib/${ARCH}-linux-gnu/plugins \
    NCCL_TESTS_PATH=/opt/nccl-tests \
    NCCL_DEBUG=INFO \
    FI_PROVIDER=efa \
    ETCD_CPP_API_DISABLE_URI_VALIDATION=1 \
    OMPI_MCA_mca_base_component_path=/opt/amazon/openmpi/lib/openmpi \
    UCX_TLS=sm,cuda_copy,cuda_ipc,efa \
    RUSTUP_HOME=/usr/local/rustup \
    CARGO_HOME=/usr/local/cargo \
    PIP_BREAK_SYSTEM_PACKAGES=1 \
    PATH=/opt/amazon/openmpi/bin:/usr/local/ucx/bin:/opt/nccl-tests/build:/usr/local/cargo/bin:/usr/local/bin:/usr/local/cuda/bin:${PATH} \
    LD_LIBRARY_PATH=/usr/local/ucc/lib:/usr/local/ucx/lib:/usr/local/ucx/lib/ucx:/opt/amazon/openmpi/lib:/opt/amazon/efa/lib:/opt/aws-ofi-nccl/lib:/opt/gdrcopy/lib64:/usr/local/nixl/lib/x86_64-linux-gnu:/usr/local/nixl/lib/x86_64-linux-gnu/plugins:/usr/local/lib:${LD_LIBRARY_PATH}

# Install runtime dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    libnuma1 \
    libhwloc15 \
    libevent-2.1-7 \
    libevent-core-2.1-7 \
    libevent-pthreads-2.1-7 \
    libgomp1 \
    libgflags2.2 \
    openssh-server \
    openssh-client \
    libcpprest2.10 \
    libgrpc++1.51 \
    libprotobuf32 \
    libgrpc29 \
    wget \
    ca-certificates \
    libnl-3-200 \
    libnl-route-3-200 \
    liburing2 \
    libclang-dev \
    git \
    curl \
    jq \
    && rm -rf /var/lib/apt/lists/*

# Install etcd binary
RUN cd /tmp && \
    wget https://github.com/etcd-io/etcd/releases/download/v3.5.11/etcd-v3.5.11-linux-amd64.tar.gz && \
    tar xzf etcd-v3.5.11-linux-amd64.tar.gz && \
    cp etcd-v3.5.11-linux-amd64/etcd /usr/local/bin/ && \
    cp etcd-v3.5.11-linux-amd64/etcdctl /usr/local/bin/ && \
    rm -rf etcd-v3.5.11-linux-amd64* && \
    chmod +x /usr/local/bin/etcd /usr/local/bin/etcdctl

# Copy all built artifacts from build stage
COPY --from=build /usr/local /usr/local
COPY --from=build /opt/amazon /opt/amazon
COPY --from=build /opt/gdrcopy /opt/gdrcopy
COPY --from=build /opt/aws-ofi-nccl /opt/aws-ofi-nccl
COPY --from=build /opt/nccl-tests /opt/nccl-tests

# Copy Python site-packages (includes NIXL Python bindings)
COPY --from=build /usr/local/lib/python3.12/dist-packages /usr/local/lib/python3.12/dist-packages

# Configure SSH
RUN mkdir -p /var/run/sshd /run/sshd && \
    ssh-keygen -A && \
    sed -i 's/PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config && \
    sed -i 's/#PermitUserEnvironment no/PermitUserEnvironment yes/' /etc/ssh/sshd_config && \
    sed -i 's/#PubkeyAuthentication.*/PubkeyAuthentication yes/' /etc/ssh/sshd_config && \
    echo "PermitRootLogin yes" >> /etc/ssh/sshd_config && \
    sed -i 's/#PermitEmptyPasswords.*/PermitEmptyPasswords yes/' /etc/ssh/sshd_config

RUN sed -i 's/[ #]\(.*StrictHostKeyChecking \).*/\1no/g' /etc/ssh/ssh_config && \
    echo "UserKnownHostsFile /dev/null" >> /etc/ssh/ssh_config && \
    sed -i 's/#\(StrictModes \).*/\1no/g' /etc/ssh/sshd_config && \
    mkdir -p /root/.ssh && \
    chmod 700 /root/.ssh && \
    printf "Host *\n  StrictHostKeyChecking no\n  UserKnownHostsFile /dev/null\n  LogLevel ERROR\n" > /root/.ssh/config && \
    chmod 600 /root/.ssh/config

# Generate SSH keys
RUN ssh-keygen -q -t rsa -N '' -f /root/.ssh/id_rsa && \
    cp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys && \
    chmod 600 /root/.ssh/id_rsa /root/.ssh/authorized_keys && \
    chmod 644 /root/.ssh/id_rsa.pub

############################
# Step 4: Verify UCC was copied and configure ldconfig
############################
RUN echo "=== Verifying UCC was copied from build stage ===" && \
    ls -la /usr/local/ucc/lib/libucc.so* && \
    echo "✓ UCC libraries present"

############################
# Step 5: Configure dynamic linker (custom builds take precedence)
############################
RUN echo "# Custom-built libraries (HIGHEST priority)" > /etc/ld.so.conf.d/00-custom.conf && \
    echo "/usr/local/ucc/lib" >> /etc/ld.so.conf.d/00-custom.conf && \
    echo "/usr/local/ucx/lib" >> /etc/ld.so.conf.d/00-custom.conf && \
    echo "/usr/local/ucx/lib/ucx" >> /etc/ld.so.conf.d/00-custom.conf && \
    echo "/opt/amazon/openmpi/lib" >> /etc/ld.so.conf.d/00-custom.conf && \
    echo "/opt/amazon/efa/lib" >> /etc/ld.so.conf.d/00-custom.conf && \
    echo "/usr/local/nixl/lib/x86_64-linux-gnu" > /etc/ld.so.conf.d/01-nixl.conf && \
    echo "/usr/local/nixl/lib/x86_64-linux-gnu/plugins" >> /etc/ld.so.conf.d/01-nixl.conf && \
    echo "/opt/gdrcopy/lib64" > /etc/ld.so.conf.d/02-gdrcopy.conf && \
    echo "/opt/aws-ofi-nccl/lib" > /etc/ld.so.conf.d/03-aws-ofi-nccl.conf && \
    ldconfig && \
    echo "=== Verifying UCC is in ldconfig ===" && \
    ldconfig -p | grep libucc && \
    echo "✓ ldconfig configured with UCC"


############################
# Final Verification
############################
RUN echo "=== CUDA 12.8 Base Image Verification ===" && \
    nvcc --version && \
    echo "=== Verifying PyTorch (should work without HPC-X) ===" && \
    python3 -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.version.cuda}'); print(f'CUDA available: {torch.cuda.is_available()}')" && \
    echo "=== Verifying Rust ===" && \
    rustc --version && cargo --version && \
    echo "=== Verifying HPC-X removal ===" && \
    (ls /opt/hpcx 2>/dev/null && echo "ERROR: HPC-X still present!" && exit 1 || echo "✓ HPC-X completely removed") && \
    echo "=== Verifying custom UCX ===" && \
    ucx_info -v && \
    ls -la /usr/local/ucx/lib/libucp* && \
    echo "=== Verifying custom MPI ===" && \
    mpirun --version && \
    ompi_info | grep -i ucx && \
    echo "=== Verifying library paths (no HPC-X deps) ===" && \
    ldconfig -p | grep -E "(ucx|ucp|uct)" | head -5 && \
    echo "=== Verifying NIXL Python bindings ===" && \
    python3 -c "import nixl; print(f'NIXL module: {nixl}'); print(f'NIXL file: {nixl.__file__}')" && \
    echo "=== Testing UCX has no HPC-X dependencies ===" && \
    ldd /usr/local/ucx/lib/libucp.so | grep -i hpcx && echo "ERROR: Found HPC-X dependency!" && exit 1 || echo "✓ No HPC-X dependencies in UCX" && \
    echo "=== All verifications passed ===" && \
    echo "CUDA 12.8 base image ready (HPC-X free, custom UCX v1.19.0, custom OpenMPI)"

WORKDIR /workspace
CMD ["/bin/bash"]
