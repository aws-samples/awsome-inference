# Quantization

Models keep getting bigger. To keep cost of inference low, we need novel ways to compress models.

[[image:./model_size.png]]


Ways to compress models:

1. Pruning: 


## How to quantize models post-training to accelerate inference?

## What is quantization?


## Quantization basics?


## Quantization methods?


## Evaluating quantization methods


## Resources

1. [A Visual Guide to Quantization](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization) 
2. [Quantization Fundamentals with Hugging Face](https://learn.deeplearning.ai/courses/quantization-fundamentals/lesson/1/introduction)
3. [Quantization in Depth](https://www.deeplearning.ai/short-courses/quantization-in-depth/)
4. [How Fireworks evaluates quantization precisely and interpretably](https://fireworks.ai/blog/fireworks-quantization)
