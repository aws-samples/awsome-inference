# Inference on standard datasets

Inference on standard open source datasets is crucial to evaluate quality of deep learning models. This is useful not only when deciding which model to use for a particular application, but also useful when judging the efficacy of compression techniques such as pruning or quantization. Here, we will start with providing scripts for inference on [MMLU Pro](https://github.com/TIGER-AI-Lab/MMLU-Pro/tree/main?tab=readme-ov-file) dataset with local models or models hosted on Bedrock. Addition of more datasets will follow.

For more details on the MMLU Pro dataset, please refer to the [Huggingface Datasets](https://huggingface.co/datasets/TIGER-Lab/MMLU-Pro?row=0) page.




